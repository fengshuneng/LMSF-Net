# Ultralytics YOLO ğŸš€, AGPL-3.0 license
# YOLO11 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 80 # number of classes
scales: # model compound scaling constants, i.e. 'model=yolo11n.yaml' will call yolo11.yaml with scale 'n'
  # [depth, width, max_channels]
  # n: [0.50, 0.25, 1024] # summary: 319 layers, 2624080 parameters, 2624064 gradients, 6.6 GFLOPs
  s: [0.50, 0.50, 1024] # summary: 319 layers, 9458752 parameters, 9458736 gradients, 21.7 GFLOPs
  m: [0.50, 1.00, 512] # summary: 409 layers, 20114688 parameters, 20114672 gradients, 68.5 GFLOPs
  l: [1.00, 1.00, 512] # summary: 631 layers, 25372160 parameters, 25372144 gradients, 87.6 GFLOPs
  x: [1.00, 1.50, 512] # summary: 631 layers, 56966176 parameters, 56966160 gradients, 196.0 GFLOPs

# 0-P1/2
# 1-P2/4
# 2-P3/8
# 3-P4/16
# 4-P5/32

# YOLO11n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, starnet_s050, []]  # 4
  - [-1, 1, SPPF, [1024, 5]]  # 5
  - [-1, 2, C2PSA, [1024]] # 6

# YOLO11n head
head:
  - [-1, 1, Conv, [512, 1, 1]] # 7
  - [4, 1, Conv, [512, 1, 1]] # 8
  - [[-1, 3, -2], 1, Zoom_cat, []]  # 9 cat backbone P4
  - [-1, 2, C3k2, [512, False]]  # 10

  - [-1, 1, Conv, [256, 1, 1]] # 11
  - [2, 1, Conv, [256, 1, 1]] # 12
  - [[-1, 2, -2], 1, Zoom_cat, []]  # 13  cat backbone P3
  - [-1, 2, C3k2, [256, False]]  # 14 (P3/8-small)
  - [-1, 1, SimAM, [1e-4]]

  - [-1, 1, Conv, [256, 3, 2]] # 16
  - [[-1, 11], 1, Concat, [1]]  # 17 cat head P4
  - [-1, 2, C3k2, [512, False]]  # 18 (P4/16-medium)

  - [-1, 1, Conv, [512, 3, 2]] # 19
  - [[-1, 6], 1, Concat, [1]]  # 20 cat head P5
  - [-1, 2, C3k2, [1024, True]]  # 21 (P5/32-large)

  - [[2, 3, 4], 1, ScalSeq, [256]] # 22 args[inchane]
  # - [[18, -1], 1, Add, []] # 
  - [[15, -1], 1, asf_attention_model, []] # 23 å¯ä»¥è‡ªè¡Œæ›¿æ¢ï¼Œä¸Šé¢çš„æ˜¯æ™®é€šçš„addï¼Œè¿™ä¸ªæ˜¯asfæ–‡ç« ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶

  - [-1, 1, nn.Upsample, [None, 2, 'nearest']] # 24
  - [[-1, 1], 1, Concat, []]  # 25  cat backbone P2
  - [-1, 2, C3k2, [128, False]]  # 26 (P2/4-small)
  - [-1, 1, SimAM, [1e-4]]

  - [[1, 23, 18], 1, ScalSeq, [128]] # 28 args[inchane]
  # - [[29, -1], 1, Add, []] # 31
  - [[27, -1], 1, asf_attention_model, []] # 29 å¯ä»¥è‡ªè¡Œæ›¿æ¢ï¼Œä¸Šé¢çš„æ˜¯æ™®é€šçš„addï¼Œè¿™ä¸ªæ˜¯asfæ–‡ç« ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶

  - [[29, 23, 18, 21], 1, Detect_SEAM, [nc]]  # RTDETRDecoder(P3, P4, P5)